{
  "name": "Music-Theory-In-Virtual-Reality",
  "tagline": "The Best Music Experience In Virtual Reality!",
  "body": "# Description & Motivation\r\nWhen was the last time you went to a music concert in an huge auditorium and realized that your seat location in the hall actually was making a significant difference to the sound you were listening to?  \r\nWhen was the last time you tried to feel what each instrument's importance is when you listen to a song?  \r\nWhat was the last time you listened to your favorite song and remember exactly what each piece of instrument brings the \"vibe\" to the whole music experience?  \r\n**If you are unsure about your answer, then it's the time!**\r\n\r\nAccording to the statistics, [The Average American Listens to Four Hours of Music Each Day](http://www.spin.com/2014/06/average-american-listening-habits-four-hours-audio-day/). This was our motivation to bring this experience in Virtual Reality!  \r\nAfter this experience, the user will have a significant insight into the following data:  \r\n1. Music and Acoustics Experience inside and outside a concert hall.  \r\n2. Every single instrument's contribution to a song and overall musical experience.  \r\n\r\nThis immersive VR experience can be deployed to Google Cardboard and/or Oculus Rift. It has been developed using Unity3D Gaming Engine. This project was developed as a class project for the Virtual Reality (CIS6930) class at University of Florida.\r\nThe team consists of 3 graduate students:  \r\n\r\n1. Izhar Shaikh (https://github.com/its-izhar)\r\n\r\n2. Salim Chaouqi (https://github.com/Salimchaouqi)\r\n\r\n3. Kannabiran Maheswaran (https://github.com/KannaNoob)  \r\n\r\n\r\n# Video Link  \r\n[![](http://img.youtube.com/vi/9-6Gq8um76E/0.jpg)](http://www.youtube.com/watch?v=9-6Gq8um76E)  \r\n\r\n\r\n\r\n# \"Insight Objective\" of the Virtual Reality Experience  \r\nWe had two major insights that we wanted to user to take from this VR experience:  \r\n\r\n\r\n**1. The first objective was to let user know what does a concert hall bring to the sound of a musical performance.**  \r\nThis is of course determined by the acoustics of the concert hall. An insight we wanted people to have is that in front of the stage in a concert hall is the location where all the sound reflections re-converge creating a very muddy, and very echoey sound.  \r\n\r\n\r\n**2. The Second objective was to allow the user to see what each musical instrument brings to the sound of the song.**  \r\nThis is determined by the change in the sound of the song as the user enables/disables a particular instrument (similar to \"a conductor\" in an orchestra). A very interesting part you will notice is that in the song 'Never going to give you' up by Rick Astetly, the electric guitar part has much less of a significant roll then in the song 'In the end' by Linkin park, which has an essential electric guitar part. An interesting fact we would like users to notice is that 'Never gonna give you up' could be considered a Pop song, whereas 'In the end' is a Rock song, which sparks an interesting correlation depending on genre.  \r\n\r\n\r\n# Benefits of experiencing this in VR\r\nWe feel that when experiencing music in VR, it allows you to be more enveloped and focused on what you are listening too similar to what a conductors focus would be. It allows you to ignore any outside distractions and focus on the task at hand. Experiencing this in VR also gives you a sense of actually being inside a \"real\" concert hall as an attendant of a music concert, which is quite of a unique experience in itself.  \r\n\r\n\r\n# Technical Description  \r\nThe acoustics of any hall, as perceived by a member of the audience, consist of three factors: volume, equalization, and reverberation (i.e., reflected sound).  \r\nIn a concert hall, the sound one hears consists of 1) directly radiated sound and 2) reflected sound.  \r\n1) Directly radiated sound, referred to as primary sound, is the sound that reaches the ear directly from the source.    \r\n2) Reflected sound is the sound that reaches the ear after being reflected off the various surfaces of the hall (walls, ceiling, etc.)  \r\n\r\n* Most of our research was spent in understanding how the acoustics of a concert hall work, and how to create as close as possible digital representation in the short time span we had for this project.\r\n* The reverb zones are placed strategically to emulate a real concert. When standing in front of the musicians the music sounds unpleasant due to the fact that sound waves travel longer before converging and the reflection causes a muddled sound in the convergence area.  The best spots to be at in a concert as seen in the video accurately reflects how sound waves travel and reflect off walls to produce the music that an artist would like you listen to. This was done with the help of Reverb Zones and 3D audio controlled by a custom curve.\r\n* The scripts use RayCasting to determine which object was selected and a function to toggle between the songs and the specific instruments are called.\r\nFor turning off the concert hall we simply used a tag zones, and set the concert hall, reverb zones to that tag and setActive to false when the user wanted to disable the concert hall.  \r\n\r\n\r\n# How the experience leveraged concepts found in the VR Book sections Chapter 19?  \r\n**Hardware:** For hardware to be least significant factor adding to the Simulator Sickness, we  made sure the HMD is free of flickers, used a light weighted phone (LG G2) with a Plastic Google Cardboard with Good lenses. In addition, we used lightweight OTG cable with PS3 controller for navigation to nullify counterbalance and finally we used a bluetooth-paired audio headset.  \r\n\r\n**System Calibration:** Since the HMD and Joystick were tightly attached, Pupillary Distance (PD) was proper.  \r\n\r\n**Latency reduction:** Scripts are written in a manner that would reduce the end-to-end delays as much as possible. We repeatedly tested the system for FPS lags, so dropped frames and increased latency won't occur.  \r\n\r\n**General Design:** Deleted directional light to reduce shadows as much as possible, this added an average of 40 FPS increase! we wanted to make sure the system ran with as few FPS lags as possible considering we had a many large sound files. We implemented this is by having a minimum amount of graphical models as possible to where the user can still understand the scene and have low FPS!  \r\n\r\n**Interaction design:** We used PS3 controller with OTG cable, allowed user to select what instruments are on and off as well as to enable/disable the concert hall.  \r\n\r\n**Usage:** Safety: Enough room for user to move and be comfortable.  \r\nHygeine: Wiped all instruments with Lysol wipes.  \r\nNew users: Encouranged them to proceed with slow head motions.  \r\nSickness: Made sure the user is not sick and we respect their decision if they want to stop the experiment or not try it all.  \r\nAdaption/Re-adaption: If the user felt sick, we advised them not to drive car for next 30 minutes.  \r\nMeasuring Sickness: Used the post exposure simulator sickness questionnaire. \r\n\r\n\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}